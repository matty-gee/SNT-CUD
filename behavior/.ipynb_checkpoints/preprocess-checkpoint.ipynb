{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "user = os.path.expanduser('~')\n",
    "sys.path.insert(0, user + '/Dropbox/Projects/Code/utilities')\n",
    "sys.path.insert(0, user + '/Dropbox/Projects/Code/snt_behavior/preprocessing')\n",
    "sys.path.insert(0, '..') \n",
    "\n",
    "from project_utils import *\n",
    "from snt_info import *\n",
    "from parsing_functions import * \n",
    "from preprocess_snt import preprocess_snt\n",
    "from standard_modules import *\n",
    "from circ_stats import *\n",
    "import csv\n",
    "from functools import reduce\n",
    "\n",
    "char_roles = ['first', 'second', 'assistant', 'powerful', 'boss', 'neutral']\n",
    "ver_skincolor = [['Brown','Brown','Brown','White','White','Brown'],\n",
    "                 ['White','White','White','Brown','Brown','White'],\n",
    "                 ['Brown','Brown','Brown','White','White','White'],\n",
    "                 ['White','White','White','Brown','Brown','Brown']]\n",
    "ver_gender = [['Woman','Man','Man','Woman','Man','Woman'],\n",
    "              ['Woman','Man','Man','Woman','Man','Woman'],\n",
    "              ['Man','Woman','Woman','Man','Woman','Man'],\n",
    "              ['Man','Woman','Woman','Man','Woman','Man']]\n",
    "\n",
    "# names frm dots\n",
    "ver_name = [['Olivia','Peter','Anthony','Newcomb','Hayworth','Kayce'],\n",
    "            ['Olivia','Peter','Anthony','Newcomb','Hayworth','Kayce'],\n",
    "            ['Peter','Olivia','Kayce','Newcomb','Hayworth','Anthony'],\n",
    "            ['Peter','Olivia','Kayce','Newcomb','Hayworth','Anthony']]\n",
    "\n",
    "syn_dir     = '/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD'\n",
    "data_dir    = f'{syn_dir}/Data'\n",
    "beh_dir     = f'{data_dir}/Behavior'\n",
    "summary_dir = f'{data_dir}/Summary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 logs\n",
      "All logs appear to be processed\n",
      "Behavioral preprocessing is completed\n"
     ]
    }
   ],
   "source": [
    "# parse the logs\n",
    "logs = glob.glob(f'{data_dir}/Behavior/Logs/*.log')\n",
    "print(f'Found {len(logs)} logs')\n",
    "xlsx = [f for f in glob.glob(f'{beh_dir}/Organized/*.xlsx') if '~$' not in f]\n",
    "if len(logs) == len(xlsx):\n",
    "    print('All logs appear to be processed')\n",
    "else:\n",
    "    for f in files:\n",
    "        if not os.path.exists(f):\n",
    "            parse_log(f, exp='KB', fmri=True)\n",
    "            \n",
    "# compute the behavioral geometry\n",
    "if os.path.exists(f'{summary_dir}/SNT-task_n{len(xlsx)}.xlsx'):\n",
    "    print('Behavioral preprocessing is completed')\n",
    "else:\n",
    "    xlsx_files = glob.glob(beh_dir + '/Organized/*.xlsx')\n",
    "    preprocess_snt(beh_dir, xlsx_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sr_df = pd.read_csv(glob.glob(data_dir + '/Questionnaires/CURRENT*')[0])\n",
    "\n",
    "# # exclude cols (phi, timestamps, others)\n",
    "# phi = ['name','phi','phonenum', 'timestamp', 'complet']\n",
    "# cols = sr_df.columns\n",
    "# cols_incl = list(cols[[not any(phi in c for phi in phi) for c in cols]])\n",
    "# sr_df = sr_df[cols_incl]\n",
    "\n",
    "# # sub ids\n",
    "# sub_list = [sub.replace('P','') for sub in sr_df['record_id'].values]\n",
    "# sub_list[np.where(np.array(sub_list)=='21002_20013')[0][0]] = '21002'\n",
    "# sr_df['record_id'] = sub_list\n",
    "# sr_df.rename(columns={'record_id':'sub_id'}, inplace=True)\n",
    "\n",
    "# # sni \n",
    "# num_ppl = ((sr_df['sni_marital_status'] == 1) * 1).values\n",
    "# network_div = ((sr_df['sni_marital_status'] == 1) * 1).values\n",
    "# other_sni = sr_df[['sni_numbr_children_contact','sni_relatives_talk_to_biweekly',\n",
    "#                     'sni_friends_contact_biweekly','sni_religious_affiliation_contact_biweekly',\n",
    "#                     'sni_students_teachers_biweekly_contact','sni_coworkers_biweekly_contact',\n",
    "#                     'sni_neighboors_biweekly_contact','sni_volunteers_biweekly_contact',\n",
    "#                     'sni_other_volunteer_grp_member_biweekly_contact','sni_total_nmbr_other_volunteers_biweekly_contact']]\n",
    "\n",
    "# num_ppl = num_ppl + np.sum(np.nan_to_num(other_sni.values), 1)\n",
    "# network_div = network_div + np.sum((np.nan_to_num(other_sni.values) > 0) * 1, 1)\n",
    "\n",
    "# parents_sni = sr_df[['sni_in_laws_talk_biweekly','sni_parents_contact_biweekly']]\n",
    "# both = (parents_sni == 'both') * 2\n",
    "# mother = (parents_sni == 'mother') * 1\n",
    "# father = (parents_sni == 'father') * 1\n",
    "\n",
    "# sr_df['sni_num_ppl'] = num_ppl + np.sum(both.values + mother.values + father.values, 1)\n",
    "# sr_df['sni_network_div'] = network_div + np.sum(both.values>0, 1) + np.sum(mother.values>0, 1) + np.sum(father.values>0, 1)\n",
    "\n",
    "# sr_df.to_excel(data_dir + '/Summary/Questionnaires_n' + str(len(sr_df)) + '.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory processing completed\n"
     ]
    }
   ],
   "source": [
    "mem_df = pd.read_excel(glob.glob(f'{data_dir}/Summary/SNT-memory*_raw.xlsx')[0])\n",
    "\n",
    "FV = ['Newcomb','Newcomb','Hayworth','Kayce','Jessica','Anthony','Jessica','Chris',\n",
    "      'Kayce','Newcomb','Hayworth','Jessica','Kayce','Anthony','Anthony','Kayce',\n",
    "      'Chris','Newcomb','Anthony','Chris','Kayce','Chris','Newcomb',\n",
    "      'Jessica','Hayworth','Jessica','Hayworth','Anthony','Chris', 'Hayworth']\n",
    "MV = ['Newcomb','Newcomb','Hayworth','Anthony','Chris','Kayce','Chris','Jessica','Anthony','Newcomb',\n",
    "      'Hayworth','Chris','Anthony','Kayce','Kayce','Anthony','Jessica','Newcomb','Kayce','Jessica',\n",
    "      'Anthony','Jessica','Newcomb','Chris','Hayworth','Chris','Hayworth','Kayce','Jessica','Hayworth']\n",
    "roles = ['powerful','powerful','boss','neutral','first','assistant','first','second','neutral','powerful',\n",
    "         'boss','first','neutral','assistant','assistant','neutral','second','powerful','assistant','second',\n",
    "         'neutral','second','powerful','first','boss','first','boss','assistant','second','boss']\n",
    "ques = [f'memory_{r+1}_{role}' for r,role in enumerate(roles)]\n",
    "\n",
    "dfs = []\n",
    "for s,sub in mem_df.iterrows():\n",
    "    v = sub.Task_ver\n",
    "    if v in [1,2]: ans = np.array([x.lower() for x in FV])\n",
    "    else:          ans = np.array([x.lower() for x in MV])\n",
    "    resps = np.array([x.lower() for x in list(sub.values[2:])])\n",
    "    correct = list((resps==ans) * 1)\n",
    "    acc = np.mean(correct)\n",
    "    \n",
    "    df = pd.DataFrame([sub.Sub_id, v, acc] + correct).T\n",
    "    df.columns = ['sub_id','task_version','memory_mean'] + ques\n",
    "    dfs.append(df)\n",
    "mem_df = pd.concat(dfs)\n",
    "mem_df.to_excel(f'{data_dir}/Summary/SNT-memory_n{len(mem_df)}_processed.xlsx')\n",
    "print('Memory processing completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 dots jpgs\n",
      "Dots appear to be processed\n"
     ]
    }
   ],
   "source": [
    "# parse the dots\n",
    "dots_dir = f'{data_dir}/Dots'\n",
    "jpgs = glob.glob(f'{dots_dir}/Dots*jpg')\n",
    "print(f'Found {len(jpgs)} dots jpgs')\n",
    "if os.path.exists(f'{data_dir}/Summary/SNT-dots_n{len(jpgs)}.xlsx'):\n",
    "    print('Dots appear to be processed')\n",
    "else:\n",
    "    dfs = []\n",
    "    for j, jpg in enumerate(jpgs):\n",
    "        print(f'{j} {jpg}', end=\"\\r\")\n",
    "        try:\n",
    "            sub_id = jpg.split('Dots_')[1].split('.jpg')[0]\n",
    "            df = define_char_coords(load_image(jpg))[1]\n",
    "            df.insert(0, 'sub_id', sub_id)\n",
    "            dfs.append(df)\n",
    "        except:\n",
    "            print(f'ERROR: {fname}')\n",
    "\n",
    "    coords_df = pd.concat(dfs)\n",
    "    coords_df.to_excel(f'{data_dir}/Summary/SNT-dots_n{len(coords_df)}.xlsx', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 confound files\n",
      "18004\n",
      "18006\n",
      "18007\n",
      "18010\n",
      "18015\n",
      "18017\n",
      "19004\n",
      "19005\n",
      "19007\n",
      "19009\n",
      "19012\n",
      "19014\n",
      "19016\n",
      "19017\n",
      "19025\n",
      "19027\n",
      "19028\n",
      "19032\n",
      "19042\n",
      "19045\n",
      "19051\n",
      "19052\n",
      "19053\n",
      "19056\n",
      "19057\n",
      "19059\n",
      "20001\n",
      "20006\n",
      "20007\n",
      "20010\n",
      "21002\n",
      "21004\n",
      "21013\n",
      "21014\n",
      "21020\n",
      "21021\n",
      "22001\n",
      "22002\n",
      "75\r"
     ]
    }
   ],
   "source": [
    "tsv_fnames = glob.glob(f'{syn_dir}/QC/cfd_files/*.tsv')\n",
    "tsv_fnames.sort()\n",
    "\n",
    "outname    = f'{summary_dir}/SNT-fMRI_QC_n{len(tsv_fnames)}.xlsx'\n",
    "overwrite  = True\n",
    "cfd_cols   = ['framewise_displacement', 'rmsd', 'std_dvars']\n",
    "# -- dvars: rate of change of BOLD signal across the entire brain at each volume\n",
    "\n",
    "if (os.path.exists(outname)) & (not overwrite):\n",
    "    print('fMRI QC is already summarized')\n",
    "else:\n",
    "    print(f'Found {len(tsv_fnames)} confound files')\n",
    "    dfs = []\n",
    "    for i, fname in enumerate(tsv_fnames):\n",
    "        \n",
    "        print(i+1, end=\"\\r\")\n",
    "        \n",
    "        with open(fname) as f: \n",
    "            cfds = [r for r in csv.reader(f, delimiter=\"\\t\", quotechar='\"')] # load\n",
    "        \n",
    "        sub_id = int(fname.split('sub-P')[-1].split('_')[0])\n",
    "        cfd_df = pd.DataFrame(cfds[1:], columns=cfds[0])\n",
    "        cfd_df.replace(to_replace='n/a', value=np.nan, inplace=True)\n",
    "        cfd_df = cfd_df.astype(float)  \n",
    "        \n",
    "        ## mean and max of confounds\n",
    "        means  = np.nanmean(cfd_df.loc[:, cfd_cols], 0)\n",
    "        maxes  = np.nanmax(cfd_df.loc[:, cfd_cols], 0)\n",
    "\n",
    "        ## find outlier volumes\n",
    "        # framewise displacement > 1 voxel (2.1mm)\n",
    "        fd_onevox   = cfd_df['framewise_displacement'] > 2.1\n",
    "        fd_onevox_n = np.sum(fd_onevox) \n",
    "        if fd_onevox_n>0:\n",
    "            print(sub_id)\n",
    "        try:  \n",
    "            fd_onevox_vols = list(np.where(fd_onevox==1)[0])\n",
    "        except:                \n",
    "            fd_onevox_vols = [np.nan] # none\n",
    "\n",
    "        # fmripreps outliers: motion or intensity spikes\n",
    "        # -- defaults are FD > 0.5 mm or DVARS > 1.5 (seems fairly conservative)\n",
    "        # -- these columns could be used as regressors in first level model\n",
    "        try: \n",
    "            cols = [c for c in cfd_df.columns if 'motion_outlier' in c]\n",
    "            outlier_vols = [np.where(cfd_df[c]==1)[0][0] for c in cols]\n",
    "        except: \n",
    "            outlier_vols = [np.nan] # none \n",
    "\n",
    "        # % of decision volumes that are outliers\n",
    "        outlier_decision   = np.round(len([v for v in outlier_vols if v in decision_epochs])/len(decision_epochs), 2) \n",
    "        fd_onevox_decision = np.round(len([v for v in fd_onevox_vols if v in decision_epochs])/len(decision_epochs), 2) \n",
    "\n",
    "        dfs.append(pd.DataFrame([sub_id] + list(means) + list(maxes) + [outlier_decision, fd_onevox_decision]).T)\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "df.columns = ['sub_id','fd_mean','rmsd_mean','std_dvars_mean','fd_max','rmsd_max','std_dvars_max','fmriprep_outlier_proportion','fd_outlier_proportion']\n",
    "df = df[['sub_id','fd_mean','fd_max','rmsd_mean','rmsd_max','std_dvars_mean','std_dvars_max','fmriprep_outlier_proportion','fd_outlier_proportion']] # reorganize\n",
    "df.to_excel(outname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "# combine data\n",
    "for fname in ['SNT-task_n*', 'SNT-memory*processed*',\n",
    "              'SNT-fMRI_QC*', 'Questionnaires_*', 'SNT-task_versions.xlsx']:\n",
    "    df = pd.read_excel(glob.glob(f'{summary_dir}/{fname}')[0])\n",
    "    df.sort_values(by='sub_id', inplace=True)\n",
    "    df['sub_id'] = df['sub_id'].astype(int)\n",
    "    dfs.append(df)\n",
    "summary_df = reduce(lambda x, y: pd.merge(x, y, on = 'sub_id'), dfs)\n",
    "first_cols = ['sub_id', 'dx']\n",
    "summary_df = summary_df[first_cols + [c for c in summary_df if c not in first_cols]]\n",
    "del summary_df['version']\n",
    "\n",
    "# task version info\n",
    "dots_df = pd.read_excel(glob.glob(f'{summary_dir}/SNT-dots*')[0])\n",
    "dots_df = summary_df[['sub_id', 'task_version']].merge(dots_df, on='sub_id')\n",
    "\n",
    "sub_dfs = []\n",
    "for s, sub in dots_df.iterrows():\n",
    "    \n",
    "    v = sub.task_version.astype(int) - 1\n",
    "    for n, name in enumerate(ver_name[v]):\n",
    "        sub.rename(index={name + '_affil':'dots_affil_' + char_roles[n]}, inplace=True)\n",
    "        sub.rename(index={name + '_power':'dots_power_' + char_roles[n]}, inplace=True)\n",
    "    gender   = pd.DataFrame(np.array(ver_gender[v]).reshape(1,-1),    columns=[c + '_gender' for c in char_roles])\n",
    "    skintone = pd.DataFrame(np.array(ver_skincolor[v]).reshape(1,-1), columns=[c + '_skincolor' for c in char_roles])\n",
    "    sub_dfs.append(sub.to_frame().T)\n",
    "    \n",
    "summary_df = summary_df.merge(pd.concat(sub_dfs), on=['sub_id','task_version'])\n",
    "summary_df.to_excel(summary_dir + '/All-data_summary_n'+str(len(summary_df)) + '.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inclusion</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>scan_date</th>\n",
       "      <th>xnat_id</th>\n",
       "      <th>notes</th>\n",
       "      <th>other_incl</th>\n",
       "      <th>memory_mean</th>\n",
       "      <th>memory_incl</th>\n",
       "      <th>missed_trials</th>\n",
       "      <th>...</th>\n",
       "      <th>rt_mean</th>\n",
       "      <th>fd_mean</th>\n",
       "      <th>fd_max</th>\n",
       "      <th>rmsd_mean</th>\n",
       "      <th>rmsd_max</th>\n",
       "      <th>std_dvars_mean</th>\n",
       "      <th>std_dvars_max</th>\n",
       "      <th>fmriprep_outlier_proportion</th>\n",
       "      <th>fd_outlier_proportion</th>\n",
       "      <th>fd_incl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18001</td>\n",
       "      <td>HC</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.109746</td>\n",
       "      <td>0.147883</td>\n",
       "      <td>0.927599</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>0.542953</td>\n",
       "      <td>1.006453</td>\n",
       "      <td>2.747418</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18002</td>\n",
       "      <td>HC</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.670429</td>\n",
       "      <td>0.156055</td>\n",
       "      <td>1.614437</td>\n",
       "      <td>0.099302</td>\n",
       "      <td>0.793133</td>\n",
       "      <td>1.010122</td>\n",
       "      <td>1.945367</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18003</td>\n",
       "      <td>HC</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.601905</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.793762</td>\n",
       "      <td>0.128853</td>\n",
       "      <td>0.520482</td>\n",
       "      <td>1.075622</td>\n",
       "      <td>1.694489</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18004</td>\n",
       "      <td>CD</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.002444</td>\n",
       "      <td>0.462666</td>\n",
       "      <td>6.367780</td>\n",
       "      <td>0.275860</td>\n",
       "      <td>3.236020</td>\n",
       "      <td>1.075255</td>\n",
       "      <td>4.718619</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inclusion  sub_id  dx scan_date  xnat_id notes  other_incl  memory_mean  \\\n",
       "0        1.0   18001  HC       NaT      NaN   NaN         1.0     0.833333   \n",
       "1        1.0   18002  HC       NaT      NaN   NaN         1.0     0.333333   \n",
       "2        1.0   18003  HC       NaT      NaN   NaN         1.0     0.466667   \n",
       "3        1.0   18004  CD       NaT      NaN   NaN         1.0     0.266667   \n",
       "\n",
       "   memory_incl  missed_trials  ...   rt_mean   fd_mean    fd_max  rmsd_mean  \\\n",
       "0          1.0            0.0  ...  4.109746  0.147883  0.927599   0.085049   \n",
       "1          1.0            3.0  ...  6.670429  0.156055  1.614437   0.099302   \n",
       "2          1.0            0.0  ...  2.601905  0.197266  0.793762   0.128853   \n",
       "3          1.0            1.0  ...  2.002444  0.462666  6.367780   0.275860   \n",
       "\n",
       "   rmsd_max  std_dvars_mean  std_dvars_max  fmriprep_outlier_proportion  \\\n",
       "0  0.542953        1.006453       2.747418                         0.04   \n",
       "1  0.793133        1.010122       1.945367                         0.02   \n",
       "2  0.520482        1.075622       1.694489                         0.01   \n",
       "3  3.236020        1.075255       4.718619                         0.38   \n",
       "\n",
       "   fd_outlier_proportion  fd_incl  \n",
       "0                   0.00      1.0  \n",
       "1                   0.00      1.0  \n",
       "2                   0.00      1.0  \n",
       "3                   0.02      1.0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize all quality control\n",
    "info = pd.read_excel(f'{syn_dir}/participants_info.xlsx')\n",
    "qc_cols = ['sub_id', 'dx', 'memory_mean', 'missed_trials', 'rt_mean','fd_mean','fd_max',\n",
    "           'rmsd_mean','rmsd_max','std_dvars_mean','std_dvars_max', 'fmriprep_outlier_proportion','fd_outlier_proportion']\n",
    "qc_df = summary_df[qc_cols]\n",
    "\n",
    "qc_df.insert(3, 'memory_incl', (qc_df['memory_mean'] > 0.20) * 1)\n",
    "qc_df.insert(5, 'missed_trials_incl', (qc_df['missed_trials'] < 10) * 1)\n",
    "qc_df.insert(15, 'fd_incl', (qc_df['fd_outlier_proportion'] < 0.05) * 1)\n",
    "qc_df = info.merge(qc_df, on=['sub_id', 'dx'], how='outer')\n",
    "inclusion = qc_df['other_incl'] * qc_df['memory_incl'] * qc_df['missed_trials_incl'] * qc_df['fd_incl']\n",
    "qc_df.insert(0, 'inclusion', inclusion)\n",
    "disp(qc_df.head(4))\n",
    "\n",
    "qc_df.to_excel(f'{syn_dir}/participants_qc_n{len(qc_df)}.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
